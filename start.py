from hotam.datasets import PE
from hotam import Pipeline
from hotam.features import DummyFeature, OneHots
from hotam.nn.models import LSTM_ER
from hotam.nn.default_hyperparamaters import get_default_hps


# from torch.nn import functional as F

# import torch 

# d =F.one_hot(
#                     torch.arange(16).expand(32,16), 
#                     num_classes=16
#                     )
# print(d.shape)


exp = Pipeline(project="debugging",
               dataset=PE(
                   tasks=["seg+label", "link", "link_label"],
                   prediction_level="token",
                   sample_level="document",
               ),
               encodings=["pos", "deprel", "dephead"],
               features=[DummyFeature(),
                         OneHots("pos"),
                         OneHots("deprel")])

exp.dataset.info

exp.fit(
    model=LSTM_ER,
    hyperparamaters=get_default_hps(LSTM_ER.name()),
    # exp_logger=exp_logger,
    ptl_trn_args=dict(
                    overfit_batches=0.1,
                    gpus=None
                    )
                    )






# import torch

# # v = torch.rand((4,3))

# # mask = torch.BoolTensor([0,1,0,1])

# # new_v = torch.tensor([[1.,1.,1.],[1.,1.,1.]])

# lengths = torch.tensor([2,4,2,6])
# max_len = torch.max(lengths)

# # print(v[mask])
# # v[mask] = new_v
# # print(v)

# # repeated_src = torch.repeat_interleave(v, lengths, dim=0)

# # print(repeated_src)

# print(torch.arange(max_len))
# print(torch.arange(max_len).expand(len(lengths), max_len))
# print(torch.arange(max_len).expand(len(lengths), max_len)  < lengths.unsqueeze(1))



# import torch

# A = torch.zeros((30,3))

# a = torch.tensor([[0.7,0.7,9],[0.6,0.6,9],[0.8,0.8,9],[0.1,0.1,9]])
# b = torch.repeat_interleave(a, torch.tensor([3,4,5,6]), dim=0)

# #b = b.unsqueeze(0)
# index = torch.tensor([1,2,3,7,8,9,10,14,15,16,17,18,22,23,24,25,26,27])
# #index = torch.tensor([list(range(i,3)) for i in [1,2,3,7,8,9,10,14,15,16,17,18,22,23,24,25,26,27]])
# #[1,2,3,7,8,9,10,14,15,16,17,18,22,23,24,25,26,27])

# index = torch.repeat_interleave(index.unsqueeze(1), repeats=1, dim=1)
# #index = torch.stack((index,index,index), dim=1)
# #index = index.unsqueeze(1)
# #print(index)
# #index = torch.tensor([[1,2],[3,4],[5,6],[7,8],[8,9,10,14,15,16,17,18,22,23,24,25,26,27])

# print(index)

# print(A.shape)
# print(index.shape)
# print(b.shape)

# A.scatter_(0, index, b)
# print(A)




# import torch

# a = torch.tensor([[[0.3353, 0.3242, 0.3405],
#          [0.3367, 0.3238, 0.3395],
#          [0.3365, 0.3251, 0.3384],
#          [0.3352, 0.3248, 0.3400],
#          [0.3370, 0.3223, 0.3407],
#          [0.3371, 0.3236, 0.3393],
#          [0.3363, 0.3216, 0.3421], #6
#          [0.3355, 0.3252, 0.3393],
#          [0.3371, 0.3236, 0.3393],
#          [0.3368, 0.3231, 0.3402],
#          [0.3374, 0.3214, 0.3412],
#          [0.3353, 0.3243, 0.3404],
#          [0.3338, 0.3247, 0.3415],
#          [0.3366, 0.3239, 0.3395],
#          [0.3361, 0.3242, 0.3397],
#          [0.3361, 0.3227, 0.3412]], #15

#         [[0.3332, 0.3260, 0.3408], #
#          [0.3336, 0.3269, 0.3395],
#          [0.3334, 0.3264, 0.3402],
#          [0.3333, 0.3263, 0.3404],
#          [0.3333, 0.3259, 0.3409],
#          [0.3330, 0.3263, 0.3407],
#          [0.3333, 0.3262, 0.3404],
#          [0.3339, 0.3255, 0.3406],
#          [0.3345, 0.3254, 0.3400],
#          [0.3348, 0.3262, 0.3390],
#          [0.3335, 0.3264, 0.3401],
#          [0.3353, 0.3244, 0.3403],
#          [0.3361, 0.3250, 0.3389],
#          [0.3351, 0.3228, 0.3420], #13 # 29
#          [0.3346, 0.3268, 0.3386],
#          [0.3356, 0.3253, 0.3391]],

#         [[0.3357, 0.3246, 0.3397],
#          [0.3372, 0.3227, 0.3401],
#          [0.3346, 0.3255, 0.3400],
#          [0.3328, 0.3261, 0.3411],
#          [0.3354, 0.3252, 0.3394],
#          [0.3346, 0.3255, 0.3399],
#          [0.3354, 0.3238, 0.3408],
#          [0.3323, 0.3273, 0.3404],
#          [0.3325, 0.3273, 0.3402],
#          [0.3323, 0.3270, 0.3407],
#          [0.3322, 0.3274, 0.3403],
#          [0.3322, 0.3276, 0.3402],
#          [0.3326, 0.3273, 0.3402],
#          [0.3328, 0.3270, 0.3402],
#          [0.3339, 0.3268, 0.3393],
#          [0.3340, 0.3269, 0.3391]],

#         [[0.3345, 0.3281, 0.3375],
#          [0.3339, 0.3281, 0.3379],
#          [0.3354, 0.3261, 0.3386],
#          [0.3355, 0.3271, 0.3374],
#          [0.3345, 0.3247, 0.3407],
#          [0.3337, 0.3288, 0.3375],
#          [0.3356, 0.3270, 0.3374],
#          [0.3350, 0.3268, 0.3382],
#          [0.3359, 0.3248, 0.3393],
#          [0.3336, 0.3273, 0.3391],
#          [0.3317, 0.3285, 0.3399],
#          [0.3342, 0.3281, 0.3377],
#          [0.3341, 0.3277, 0.3382],
#          [0.3349, 0.3257, 0.3394],
#          [0.3320, 0.3295, 0.3385],
#          [0.3315, 0.3297, 0.3387]],

#         [[0.3313, 0.3288, 0.3399],
#          [0.3321, 0.3290, 0.3389],
#          [0.3317, 0.3290, 0.3393],
#          [0.3316, 0.3292, 0.3393],
#          [0.3311, 0.3288, 0.3401],
#          [0.3328, 0.3257, 0.3415],
#          [0.3336, 0.3256, 0.3408],
#          [0.3337, 0.3267, 0.3396],
#          [0.3326, 0.3266, 0.3409],
#          [0.3342, 0.3241, 0.3416],
#          [0.3345, 0.3254, 0.3400],
#          [0.3334, 0.3237, 0.3430],
#          [0.3333, 0.3270, 0.3398],
#          [0.3350, 0.3250, 0.3400],
#          [0.3347, 0.3251, 0.3402],
#          [0.3350, 0.3232, 0.3418]],

#         [[0.3334, 0.3253, 0.3412],
#          [0.3323, 0.3263, 0.3414],
#          [0.3345, 0.3258, 0.3397],
#          [0.3339, 0.3259, 0.3402],
#          [0.3342, 0.3238, 0.3420],
#          [0.3311, 0.3275, 0.3414],
#          [0.3313, 0.3277, 0.3410],
#          [0.3309, 0.3277, 0.3413],
#          [0.3310, 0.3278, 0.3412],
#          [0.3309, 0.3275, 0.3416],
#          [0.3308, 0.3279, 0.3413],
#          [0.3308, 0.3281, 0.3412],
#          [0.3342, 0.3248, 0.3410],
#          [0.3350, 0.3243, 0.3406],
#          [0.3354, 0.3257, 0.3389],
#          [0.3336, 0.3258, 0.3406]],

#         [[0.3359, 0.3234, 0.3408],
#          [0.3370, 0.3245, 0.3385],
#          [0.3355, 0.3226, 0.3419],
#          [0.3349, 0.3264, 0.3387],
#          [0.3361, 0.3244, 0.3395],
#          [0.3355, 0.3246, 0.3399],
#          [0.3367, 0.3224, 0.3409],
#          [0.3343, 0.3252, 0.3405],
#          [0.3326, 0.3260, 0.3415],
#          [0.3349, 0.3252, 0.3399],
#          [0.3344, 0.3255, 0.3401],
#          [0.3349, 0.3240, 0.3411],
#          [0.3325, 0.3272, 0.3404],
#          [0.3327, 0.3269, 0.3404],
#          [0.3326, 0.3272, 0.3402],
#          [0.3322, 0.3274, 0.3404]],

#         [[0.3328, 0.3264, 0.3408],
#          [0.3335, 0.3267, 0.3398],
#          [0.3332, 0.3267, 0.3401],
#          [0.3352, 0.3251, 0.3397],
#          [0.3354, 0.3246, 0.3399],
#          [0.3354, 0.3261, 0.3384],
#          [0.3348, 0.3258, 0.3394],
#          [0.3363, 0.3231, 0.3406],
#          [0.3369, 0.3239, 0.3392],
#          [0.3355, 0.3218, 0.3427],
#          [0.3350, 0.3258, 0.3392],
#          [0.3365, 0.3243, 0.3392],
#          [0.3366, 0.3238, 0.3396],
#          [0.3376, 0.3214, 0.3410],
#          [0.3354, 0.3245, 0.3401],
#          [0.3331, 0.3254, 0.3415]],

#         [[0.3356, 0.3248, 0.3396],
#          [0.3359, 0.3250, 0.3391],
#          [0.3360, 0.3234, 0.3406],
#          [0.3331, 0.3270, 0.3399],
#          [0.3328, 0.3267, 0.3405],
#          [0.3324, 0.3271, 0.3405],
#          [0.3329, 0.3270, 0.3401],
#          [0.3328, 0.3263, 0.3410],
#          [0.3325, 0.3267, 0.3408],
#          [0.3324, 0.3265, 0.3411],
#          [0.3332, 0.3237, 0.3430],
#          [0.3338, 0.3237, 0.3425],
#          [0.3345, 0.3245, 0.3410],
#          [0.3335, 0.3240, 0.3425],
#          [0.3352, 0.3223, 0.3425],
#          [0.3352, 0.3233, 0.3415]],

#         [[0.3349, 0.3207, 0.3443],
#          [0.3352, 0.3245, 0.3402],
#          [0.3364, 0.3229, 0.3407],
#          [0.3360, 0.3229, 0.3411],
#          [0.3364, 0.3205, 0.3431],
#          [0.3339, 0.3237, 0.3424],
#          [0.3326, 0.3243, 0.3431],
#          [0.3349, 0.3231, 0.3420],
#          [0.3343, 0.3235, 0.3421],
#          [0.3346, 0.3219, 0.3435],
#          [0.3319, 0.3259, 0.3422],
#          [0.3319, 0.3260, 0.3421],
#          [0.3322, 0.3257, 0.3421],
#          [0.3325, 0.3254, 0.3421],
#          [0.3324, 0.3258, 0.3419],
#          [0.3319, 0.3260, 0.3421]],

#         [[0.3322, 0.3254, 0.3424],
#          [0.3346, 0.3247, 0.3407],
#          [0.3347, 0.3247, 0.3406],
#          [0.3350, 0.3259, 0.3391],
#          [0.3335, 0.3254, 0.3412],
#          [0.3348, 0.3237, 0.3415],
#          [0.3358, 0.3245, 0.3397],
#          [0.3344, 0.3219, 0.3437],
#          [0.3338, 0.3260, 0.3402],
#          [0.3353, 0.3244, 0.3403],
#          [0.3352, 0.3243, 0.3405],
#          [0.3362, 0.3223, 0.3415],
#          [0.3344, 0.3248, 0.3409],
#          [0.3327, 0.3252, 0.3420],
#          [0.3352, 0.3251, 0.3398],
#          [0.3343, 0.3252, 0.3405]],

#         [[0.3343, 0.3231, 0.3426],
#          [0.3323, 0.3268, 0.3410],
#          [0.3319, 0.3268, 0.3413],
#          [0.3318, 0.3270, 0.3413],
#          [0.3315, 0.3266, 0.3419],
#          [0.3310, 0.3271, 0.3419],
#          [0.3316, 0.3270, 0.3415],
#          [0.3314, 0.3263, 0.3423],
#          [0.3338, 0.3250, 0.3412],
#          [0.3343, 0.3250, 0.3408],
#          [0.3350, 0.3261, 0.3389],
#          [0.3336, 0.3258, 0.3406],
#          [0.3359, 0.3233, 0.3408],
#          [0.3365, 0.3239, 0.3396],
#          [0.3352, 0.3223, 0.3424],
#          [0.3343, 0.3262, 0.3395]],

#         [[0.3368, 0.3237, 0.3395],
#          [0.3373, 0.3238, 0.3389],
#          [0.3377, 0.3217, 0.3406],
#          [0.3354, 0.3247, 0.3399],
#          [0.3333, 0.3251, 0.3416],
#          [0.3354, 0.3250, 0.3396],
#          [0.3355, 0.3248, 0.3397],
#          [0.3358, 0.3225, 0.3417],
#          [0.3328, 0.3265, 0.3407],
#          [0.3328, 0.3266, 0.3407],
#          [0.3331, 0.3266, 0.3403],
#          [0.3331, 0.3264, 0.3405],
#          [0.3334, 0.3260, 0.3407],
#          [0.3337, 0.3258, 0.3405],
#          [0.3337, 0.3261, 0.3403],
#          [0.3352, 0.3245, 0.3403]],

#         [[0.3357, 0.3242, 0.3401],
#          [0.3369, 0.3255, 0.3376],
#          [0.3352, 0.3254, 0.3394],
#          [0.3369, 0.3234, 0.3397],
#          [0.3370, 0.3240, 0.3390],
#          [0.3354, 0.3225, 0.3421],
#          [0.3355, 0.3260, 0.3385],
#          [0.3368, 0.3237, 0.3396],
#          [0.3364, 0.3240, 0.3396],
#          [0.3371, 0.3220, 0.3409],
#          [0.3353, 0.3248, 0.3399],
#          [0.3334, 0.3254, 0.3412],
#          [0.3364, 0.3245, 0.3391],
#          [0.3359, 0.3244, 0.3397],
#          [0.3365, 0.3230, 0.3406],
#          [0.3332, 0.3267, 0.3401]],

#         [[0.3330, 0.3266, 0.3404],
#          [0.3337, 0.3269, 0.3394],
#          [0.3333, 0.3269, 0.3398],
#          [0.3331, 0.3271, 0.3398],
#          [0.3328, 0.3268, 0.3404],
#          [0.3324, 0.3272, 0.3404],
#          [0.3334, 0.3260, 0.3406],
#          [0.3337, 0.3252, 0.3411],
#          [0.3340, 0.3268, 0.3392],
#          [0.3327, 0.3267, 0.3406],
#          [0.3348, 0.3246, 0.3406],
#          [0.3352, 0.3253, 0.3395],
#          [0.3344, 0.3230, 0.3425],
#          [0.3341, 0.3265, 0.3394],
#          [0.3354, 0.3251, 0.3395],
#          [0.3348, 0.3251, 0.3401]],

#         [[0.3356, 0.3231, 0.3414],
#          [0.3342, 0.3261, 0.3397],
#          [0.3319, 0.3269, 0.3412],
#          [0.3343, 0.3266, 0.3391],
#          [0.3336, 0.3262, 0.3403],
#          [0.3336, 0.3249, 0.3414],
#          [0.3314, 0.3283, 0.3403],
#          [0.3312, 0.3276, 0.3412],
#          [0.3310, 0.3282, 0.3408],
#          [0.3309, 0.3283, 0.3408],
#          [0.3313, 0.3283, 0.3404],
#          [0.3312, 0.3282, 0.3406],
#          [0.3316, 0.3278, 0.3406],
#          [0.3348, 0.3250, 0.3402],
#          [0.3352, 0.3251, 0.3397],
#          [0.3348, 0.3268, 0.3384]]])


# index = torch.tensor([ 6, 13,  3,  4, 11,  4,  2,  9, 10,  0,  7,  0,  7,  5, 12,  5])


# def index_select_array(input:torch.tensor, index:torch.tensor):
#     """
#     given a input 3d tensor and a 1d index tensor selects an array at 
#     dim == -1 according to index
    
#     selecting works like following.

#         input[i][index[i]]

#     Example:

#         input = [
#                     [
#                         [0.1,0.1],
#                         [0.2,0.2],
#                         [0.3,0.3],
#                     ],
#                     [
#                         [0.4,0.4],
#                         [0.5,0.5],
#                         [0.6,0.6],
#                     ]
#                 ]
    
#     index = [2,1]


#     returns  [
#                 [0.3,0.3],
#                 [0.5,0.5],
#             ]



#     """

#     index_idxes = torch.full((index.shape[0],),index.shape[0],  dtype=torch.int16)
#     flat_idxs = cumsum_zero(index_idxes)
#     flat_input = torch.flatten(input,end_dim=-2)
#     return flat_input[flat_idx]


# #print(index.shape[0],index.shape[0], dtype=torch.int16)
# f = torch.full((index.shape[0],),index.shape[0],  dtype=torch.int16)


# def cumsum_zero(input):
#     # torch.cumsum([4,5,10]) -> [4,9,19]
#     # cumsum_zero([4,5,10]) -> [0,4,19]
#     return torch.cat((torch.zeros(1),torch.cumsum(input, dim=0)))[:-1].type(torch.int)


# flat_idx = index + torch.cat((torch.zeros(1),torch.cumsum(f, dim=0)))[:-1].type(torch.int16)

# print(flat_idx)
# a = torch.flatten(a,end_dim=-2)

# p = a[flat_idx]
# print(p.shape)